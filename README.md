# A Collection Of LLM Surveys

It's always a good way to read some surveys before diving into a new field. This collection would be updated from time to time.

The date at the end of each item shows the last time it has been updated, while "updating" means it's still being updated actively until now.

General LLMs
------
+ LLMs Survey: [https://github.com/RUCAIBox/LLMSurvey](https://github.com/RUCAIBox/LLMSurvey) (2023.11)   
+ LLMs Survey: [https://arxiv.org/abs/2402.06196](https://arxiv.org/abs/2402.06196) (2024.02)
+ LLMs Evaluation: [https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers](https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers) (2023.11)
+ Long Context: [https://github.com/Strivin0311/long-llms-learning](https://github.com/Strivin0311/long-llms-learning) (updating)
+ Instruction Tuning & Learning: [https://github.com/RenzeLou/awesome-instruction-learning](https://github.com/RenzeLou/awesome-instruction-learning) (updating)
+ Reasoning Models: [https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models) (2024.01)
+ LLM Alignment: [https://arxiv.org/pdf/2407.16216](https://arxiv.org/pdf/2407.16216) (2024.07)

Efficient LLMs
------
+ Efficient LLM Survey: [https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey) (updating)
+ Efficient LLM Paperlist: [https://github.com/horseee/Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM) (updating)
+ Efficient ViTs: [https://github.com/MingSun-Tse/Awesome-Efficient-ViT](https://github.com/MingSun-Tse/Awesome-Efficient-ViT) (2022)
+ LLMs Acceleration: [https://github.com/galeselee/Awesome_LLM_Accelerate-PaperList](https://github.com/galeselee/Awesome_LLM_Accelerate-PaperList) (updating)
+ LLMs Compression: [https://github.com/HuangOwen/Awesome-LLM-Compression](https://github.com/HuangOwen/Awesome-LLM-Compression) (updating)
+ Efficient LLM Inference: [https://arxiv.org/abs/2402.16363](https://arxiv.org/abs/2402.16363) (2024.02)
+ Efficient LLM Inference: [https://arxiv.org/pdf/2404.14294](https://arxiv.org/pdf/2404.14294) (2024.04)
+ Efficient LLM Serving: [https://arxiv.org/abs/2312.15234](https://arxiv.org/abs/2312.15234) (2023.12)
+ Prompt Compression: [https://arxiv.org/pdf/2410.12388](https://arxiv.org/pdf/2410.12388) (2024.10)
+ Speculative Decoding: [https://arxiv.org/pdf/2401.07851](https://arxiv.org/pdf/2401.07851) (2024.06)

Non-Transformer LLMs
---
+ SSM Survey: [https://arxiv.org/pdf/2404.16112](https://arxiv.org/pdf/2404.16112) (2024.04)
+ Mamba: [https://github.com/yyyujintang/Awesome-Mamba-Papers](https://github.com/yyyujintang/Awesome-Mamba-Papers) (updating)
+ Visual Mamba: [https://arxiv.org/pdf/2404.15956](https://arxiv.org/pdf/2404.15956) (2024.04)

Multimodal LLMs
------
+ Multimodal LLMs Survey: [https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) (updating)
+ Multimodal LLMs Paperlist: [https://github.com/friedrichor/Awesome-Multimodal-Papers](https://github.com/friedrichor/Awesome-Multimodal-Papers) (updating)
+ Multimodal LLMs Evaluation: [https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) (updating)
+ Multimodal fusion: [https://arxiv.org/abs/2404.18947](https://arxiv.org/abs/2404.18947) (2024.04)
+ Efficient Multimodal LLMs: [https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey](https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey) (updating)
+ Text-to-Image: [https://github.com/Yutong-Zhou-cv/Awesome-Text-to-Image](https://github.com/Yutong-Zhou-cv/Awesome-Text-to-Image) (updating)
+ Video Understanding: [https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding) (updating)

LLM Agents
------
+ LLM Agents: [https://github.com/WooooDyy/LLM-Agent-Paper-List](https://github.com/WooooDyy/LLM-Agent-Paper-List) (updating)
+ Multimodal LLM Agents: [https://arxiv.org/abs/2402.15116](https://arxiv.org/abs/2402.15116) (2024.02)
+ Multimodal LLM Agents: [https://github.com/jun0wanan/awesome-large-multimodal-agents](https://github.com/jun0wanan/awesome-large-multimodal-agents) (updating)

Diffusion
------
+ Diffusion tutorial: [https://lilianweng.github.io/posts/2021-07-11-diffusion-models/](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)
+ Diffusion Models: [https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy](https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy) (updating)
+ Diffusion Models: [https://github.com/diff-usion/Awesome-Diffusion-Models](https://github.com/diff-usion/Awesome-Diffusion-Models) (2023.12)
+ Video Diffusion Models: [https://github.com/ChenHsing/Awesome-Video-Diffusion-Models](https://github.com/ChenHsing/Awesome-Video-Diffusion-Models) (updating)
+ Video Diffusion tutorial: [https://lilianweng.github.io/posts/2024-04-12-diffusion-video/](https://lilianweng.github.io/posts/2024-04-12-diffusion-video/)

Reinforcement Learning
------
+ LLM-enhanced RL: [https://arxiv.org/abs/2404.00282](https://arxiv.org/abs/2404.00282) (2024.04)
+ LLM Alignment: [https://arxiv.org/abs/2407.16216](https://arxiv.org/abs/2407.16216) (2024.07)

Graph Neural Network
------
+ LLM in graph tasks: [https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks](https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks)

AI4Science
------
+ Survey: [https://www.nature.com/articles/s41586-023-06221-2](https://www.nature.com/articles/s41586-023-06221-2)
